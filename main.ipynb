{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries.\n",
    "import pandas as pd\n",
    "import sklearn  as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data to datafram 'df' for data preprocessing.\n",
    "data = pd.read_csv('/movie_recommendation/archive/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (722938, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 722938 entries, 0 to 722937\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    722938 non-null  int64  \n",
      " 1   title                 722934 non-null  object \n",
      " 2   genres                511966 non-null  object \n",
      " 3   original_language     722938 non-null  object \n",
      " 4   overview              604283 non-null  object \n",
      " 5   popularity            722938 non-null  float64\n",
      " 6   production_companies  337164 non-null  object \n",
      " 7   release_date          670278 non-null  object \n",
      " 8   budget                722938 non-null  float64\n",
      " 9   revenue               722938 non-null  float64\n",
      " 10  runtime               688450 non-null  float64\n",
      " 11  status                722938 non-null  object \n",
      " 12  tagline               108065 non-null  object \n",
      " 13  vote_average          722938 non-null  float64\n",
      " 14  vote_count            722938 non-null  float64\n",
      " 15  credits               497777 non-null  object \n",
      " 16  keywords              210239 non-null  object \n",
      " 17  poster_path           537553 non-null  object \n",
      " 18  backdrop_path         222426 non-null  object \n",
      " 19  recommendations       34696 non-null   object \n",
      "dtypes: float64(6), int64(1), object(13)\n",
      "memory usage: 110.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Data Analysis\n",
    "\n",
    "#checks the shape of Data\n",
    "print(\"Data shape:\", data.shape)\n",
    "\n",
    "#Give column information like columns of data and respective data's dtype\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           0\n",
      "title                        4\n",
      "genres                  210972\n",
      "original_language            0\n",
      "overview                118655\n",
      "popularity                   0\n",
      "production_companies    385774\n",
      "release_date             52660\n",
      "budget                       0\n",
      "revenue                      0\n",
      "runtime                  34488\n",
      "status                       0\n",
      "tagline                 614873\n",
      "vote_average                 0\n",
      "vote_count                   0\n",
      "credits                 225161\n",
      "keywords                512699\n",
      "poster_path             185385\n",
      "backdrop_path           500512\n",
      "recommendations         688242\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check null values in dataset\n",
    "print(data.isnull().sum())\n",
    "# checking duplicate values in data\n",
    "print(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning. As it has many missing values\n",
    "\n",
    "# droppin unnecessary title\n",
    "df = data.drop([\"production_companies\", \"popularity\", \"budget\", \"revenue\", \"status\", \"recommendations\", \"runtime\", \"vote_average\", \"backdrop_path\", \"tagline\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in title: 86982\n",
      "Duplicate title with same releasing date: 2267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                     0\n",
       "id                        0\n",
       "title                     2\n",
       "genres               198452\n",
       "original_language         0\n",
       "overview             110858\n",
       "release_date          49656\n",
       "vote_count                0\n",
       "credits              214140\n",
       "keywords             470608\n",
       "poster_path          175925\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping duplicate values\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#checking duplicates in title\n",
    "print(\"Duplicates in title:\", df.title.duplicated().sum())\n",
    "#check if duplicate titles have same release date\n",
    "print(\"Duplicate title with same releasing date:\", df[['title', 'release_date']].duplicated().sum())\n",
    "\n",
    "#Now, removing duplicate title with same relase date\n",
    "df.drop_duplicates(subset=['title', 'release_date'], inplace=True)\n",
    "\n",
    "#Removes vote_count lower than 350\n",
    "df = df[df.vote_count <= 350].reset_index()\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all null values from genre and overview with \"Nothing\"\n",
    "df.fillna(\"\", inplace=True)\n",
    "\n",
    "# Deleting movies with no genre and overview\n",
    "index = df[(df.genres == \"\") & (df.overview == \"\")].index\n",
    "df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing genres, credit and keywords \"-\" with \" \"\n",
    "df.genres = df.genres.apply(lambda x: \" \".join(x.split(\"-\")))\n",
    "df.genres = df.credits.apply(lambda x: \" \".join(x.split(\"-\")))\n",
    "df.genres = df.keywords.apply(lambda x: \" \".join(x.replace(\" \", \"\").split(\"-\")[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making tags for prediction\n",
    "df['tags'] = df.overview + \" \"+ df.genres + \" \"+ df.credits + \" \"+ df.keywords + \" \"+df.original_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deven\\AppData\\Local\\Temp\\ipykernel_20024\\2516214520.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.tags = new_df.tags.apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "# Making new framework with important features\n",
    "new_df = df[[\"id\", \"title\", \"tags\", \"poster_path\"]]\n",
    "\n",
    "# making all tags in lower case for better processing\n",
    "new_df.tags = new_df.tags.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while working underground to fix a water main brooklyn plumbers—and brothers—mario and luigi are transported down a mysterious pipe and wander into a magical new world. but when the brothers are separated mario embarks on an epic quest to find luigi. videogame plumber magicmushroom basedonvideogame aftercreditsstinger chris pratt-anya taylor-joy-charlie day-jack black-keegan-michael key-seth rogen-fred armisen-kevin michael richardson-sebastian maniscalco-khary payton-eric bauza-jessica dicicco-jeannie elias-juliet jelenic-rino romano-john dimaggio-scott menville-charles martinet-jason broad-carlos alazraqui-ashly burch-rachel butera-cathy cavadini-will collyer-django craig-willow geer-aaron hendry-andy hirsch-barbara lley-phil lamarr-jeremy maxwell-daniel mora-eric osmond-noreen reardon-lee shorten-cree summer-nisa ward-nora wyman video game-plumber-magic mushroom-based on video game-aftercreditsstinger-duringcreditsstinger-damsel in distress-brother brother relationship en'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "# Stemming\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem function to take text and give output\n",
    "\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# applying stem funcion in tags\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m new_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m, in \u001b[0;36mstem\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit():\n\u001b[1;32m----> 6\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(\u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\stem\\porter.py:673\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[1;34m(self, word, to_lowercase)\u001b[0m\n\u001b[0;32m    671\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step1c(stem)\n\u001b[0;32m    672\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step2(stem)\n\u001b[1;32m--> 673\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step4(stem)\n\u001b[0;32m    675\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step5a(stem)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# applying stem funcion in tags\n",
    "new_df[\"tags\"] = new_df[\"tags\"].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vectorization\n",
    "# importing count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# setting for 5000 most repeated words, exclude stop words.\n",
    "cv = CountVectorizer(stop_words=\"english\", max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiting tags in count vector\n",
    "vectors = cv.fit_transform(new_df[\"tags\"]).toarray() # changes it intto array to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names()[80:85]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similartiy vector with cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# calculation similarity of each movie with all movies\n",
    "similarity = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#similarity of each movie with all movies\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msimilarity\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity' is not defined"
     ]
    }
   ],
   "source": [
    "#similarity of each movie with all movies\n",
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model testing\n",
    "#making funtion to find movie and give similar movies as return\n",
    "def recommend(movies):\n",
    "    movie_index = new_df[new_df.title == movies].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movies_list = sorted(list(enumerate(distances)), reverse=True, key = lambda x:x[1])[1:6]\n",
    "    \n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking similar movies test 1\n",
    "recommend(\"Batman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 2\n",
    "recommend(\"Black Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making portable movie pickle file to trasport\n",
    "pickle.dump(new_df, open(\"movies.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making portable movie pickle file to transport\n",
    "pickle.dump(similarity, open(\"similarity.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 19:35:02.502 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\deven\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# first import streamlit and pickle \n",
    "import streamlit as st\n",
    "import pickle\n",
    "\n",
    "# extract the new_df dataframe from movies.pkl\n",
    "movies_list = pickle.load(open(\"movies.pkl\", \"rb\"))\n",
    "# extract the titles of movies\n",
    "movies_list_title = movies_list[\"title\"].values\n",
    "\n",
    "# extract the similarity which contain our cosine similarity values\n",
    "similarity = pickle.load(open(\"similarity.pkl\", \"rb\"))\n",
    "\n",
    "\n",
    "# make a recommend function which will take movie title and return 5 similar movies with their posters\n",
    "def recommend(movie):\n",
    "    movie_index = movies_list[movies_list[\"title\"] == movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    sorted_movie_list = sorted(list(enumerate(distances)), reverse=True,\n",
    "                               key=lambda x:x[1])[1:6]\n",
    "\n",
    "    recommended_movies = []\n",
    "    recommended_posters = []\n",
    "    for i in sorted_movie_list:\n",
    "        poster_path = movies_list[\"poster_path\"][i[0]]\n",
    "        recommended_movies.append(movies_list.iloc[i[0]].title)\n",
    "        recommended_posters.append(\"https://image.tmdb.org/t/p/original\"+poster_path)\n",
    "\n",
    "    return recommended_movies,  recommended_posters\n",
    "\n",
    "\n",
    "\n",
    "# Create title for your stream lit page\n",
    "st.title(\"Project Movie Recommender System\")\n",
    "\n",
    "# Create a input box for movies name \n",
    "selected_movie_name = st.selectbox(\n",
    "    \"What is the movie name?\",\n",
    "    movies_list_title\n",
    ")\n",
    "\n",
    "# create a recommend button with function of displaying recommended movies and movie posters\n",
    "if st.button(\"Recommend\"):\n",
    "    recommendation, movie_posters = recommend(selected_movie_name)\n",
    "\n",
    "    col1, col2, col3, col4, col5 = st.columns(5)\n",
    "\n",
    "    with col1:\n",
    "        st.write(recommendation[0])\n",
    "        st.image(movie_posters[0])\n",
    "    with col2:\n",
    "        st.write(recommendation[1])\n",
    "        st.image(movie_posters[1])\n",
    "    with col3:\n",
    "        st.write(recommendation[2])\n",
    "        st.image(movie_posters[2])\n",
    "    with col4:\n",
    "        st.write(recommendation[3])\n",
    "        st.image(movie_posters[3])\n",
    "    with col5:\n",
    "        st.write(recommendation[4])\n",
    "        st.image(movie_posters[4])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
